{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação e Pré Requisitios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar Google Chrome. _Rodar Manualmente em WSL_\n",
    "\n",
    "``` bash\n",
    "wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -\n",
    "echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" | sudo tee /etc/apt/sources.list.d/google-chrome.list\n",
    "sudo apt update && sudo apt install -y google-chrome-stable\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalar depenências utilizando `-venv`\n",
    "\n",
    "``` bash\n",
    "# configura ambiente virtual\n",
    "python3 -m venv venv\n",
    "\n",
    "# ativa ambiente virtual\n",
    "source venv/bin/activate\n",
    "\n",
    "# instalar dependências \n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilitário para exibir imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, HTML\n",
    "\n",
    "def display_images_grid(images: Iterator[str]):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    display(HTML(\n",
    "        ''.join([\n",
    "            f'<img src=\"{img}\" style=\"max-width: 150px; margin: 5px; display: inline-block;\">'\n",
    "            for img in images\n",
    "        ])\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza o download das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "root:str = \"Dataset\"\n",
    "!rm -rf {root}\n",
    "\n",
    "num_images:int = 200\n",
    "query_categorias:List[str] = [\"Spider Man\", \"Batman\"]\n",
    "variations = [\"Happy\", \"Neutral\", \"Old\", \"Timeless\", \"Surprise\"] # Quanto a quantidade de imagens não é suficiente.\n",
    "\n",
    "images: List[str] = []\n",
    "def on_save(file_path: str):\n",
    "    images.append(file_path)\n",
    "    display_images_grid(reversed(images[-8:]))\n",
    "\n",
    "import web_scapper\n",
    "for query in query_categorias:\n",
    "    web_scapper.scrape_images(query, num_images=num_images, main_folder=root, on_save=on_save, variations=variations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#if using Theano with GPU\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_split, val_split = 0.7, 0.15\n",
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# helper function to load image and return it and input vector\n",
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
    "              in os.walk(category) for f in filenames \n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    for img_path in images:\n",
    "        img, x = get_image(img_path)\n",
    "        data.append({'x':np.array(x[0]), 'y':c})\n",
    "\n",
    "# count the number of classes\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_val = int(train_split * len(data))\n",
    "idx_test = int((train_split + val_split) * len(data))\n",
    "train = data[:idx_val]\n",
    "val = data[idx_val:idx_test]\n",
    "test = data[idx_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
    "x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
    "x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# convert labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "print(\"finished loading %d images from %d categories\"%(len(data), num_classes))\n",
    "print(\"train / validation / test split: %d, %d, %d\"%(len(x_train), len(x_val), len(x_test)))\n",
    "print(\"training data shape: \", x_train.shape)\n",
    "print(\"training labels shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a reference to VGG's input layer\n",
    "inp = vgg.input\n",
    "\n",
    "# make a new softmax layer with num_classes neurons\n",
    "new_classification_layer = Dense(num_classes, activation='softmax')\n",
    "\n",
    "# connect our new layer to the second to last layer in VGG, and make a reference to it\n",
    "out = new_classification_layer(vgg.layers[-2].output)\n",
    "\n",
    "# create a new network between inp and out\n",
    "model_new = Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all layers untrainable by freezing weights (except for last layer)\n",
    "for l, layer in enumerate(model_new.layers[:-1]):\n",
    "    layer.trainable = False\n",
    "\n",
    "# ensure the last layer is trainable/not frozen\n",
    "for l, layer in enumerate(model_new.layers[-1:]):\n",
    "    layer.trainable = True\n",
    "\n",
    "model_new.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model_new.fit(x_train, y_train,\n",
    "                         batch_size=12,\n",
    "                         epochs=10, \n",
    "                         validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar e Carregar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 1: Salvar o modelo completo\n",
    "model_new.save('modelo_categorias.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if \"model_new\" not in locals():\n",
    "    model_new = load_model('modelo_categorias.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def get_probabilities(probs):\n",
    "  cat = list(map(lambda x: x.replace(root + \"/\", \"\"), categories))\n",
    "\n",
    "  joined = list(zip(cat, probs))\n",
    "  joined.sort(key=lambda x: x[1], reverse=True) # sort by the highest probability\n",
    "  return joined\n",
    "\n",
    "\n",
    "# Create a file upload widget\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='image/*',  # Accept all file types\n",
    "    multiple=True      # Allow only one file at a time\n",
    ")\n",
    "\n",
    "display(upload_widget)\n",
    "\n",
    "def handle_upload(_):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    display(upload_widget)\n",
    "\n",
    "    for up in upload_widget.value:\n",
    "        uploaded_file = up  \n",
    "        content = uploaded_file['content']\n",
    "        name = uploaded_file['name']\n",
    "\n",
    "        # salvar imagem no diretorio\n",
    "        with open(name, 'wb') as f:\n",
    "            f.write(content)\n",
    "\n",
    "\n",
    "        img, x = get_image(name)\n",
    "        probabilities = model_new.predict([x])\n",
    "\n",
    "        display(img, name, get_probabilities(probabilities[0]))\n",
    "\n",
    "\n",
    "# Attach the handler to the widget\n",
    "upload_widget.observe(handle_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
